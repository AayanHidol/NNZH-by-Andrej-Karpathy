{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnNS9ftQb0BwFQ9ixdNUQX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AayanHidol/NNZH-by-Andrej-Karpathy/blob/main/Building_makemore_Part_4_becoming_a_backprop_ninja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bPRX2kVSMph5",
        "outputId": "879b72cc-881b-4052-b6e7-d7ae5b787481"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-17 12:47:19--  https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.1’\n",
            "\n",
            "\rnames.txt.1           0%[                    ]       0  --.-KB/s               \rnames.txt.1         100%[===================>] 222.80K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-17 12:47:19 (6.01 MB/s) - ‘names.txt.1’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KjomINkh91Nm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlg40PHdMnkM",
        "outputId": "ef5226c6-b77c-4a33-e47d-a8a0959c3aea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhLePeyCNFQG",
        "outputId": "95a19d5f-848b-444e-c3f8-44f2baa83086"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku6L6dXyNwmU",
        "outputId": "7f8ed845-4689-47d6-88d2-70c42fe41528"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "a1dn4aADPUd3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "# Note: I am initializating many of these parameters in non-standard ways\n",
        "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
        "# implementation of the backward pass.\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ullBjB_FQKvX",
        "outputId": "8a539198-1ff8-4af7-db24-ac16ac339092"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n = batch_size # a shorter variable also, for convenience\n",
        "# construct a minibatch\n",
        "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
      ],
      "metadata": {
        "id": "L3rDpJy9SWcd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
        "\n",
        "emb = C[Xb] # embed the characters into vectors\n",
        "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "# Linear layer 1\n",
        "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "\n",
        "# BatchNorm layer\n",
        "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff**2\n",
        "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# Non-linearity\n",
        "h = torch.tanh(hpreact) # hidden layer\n",
        "\n",
        "# Linear layer 2\n",
        "logits = h @ W2 + b2 # output layer\n",
        "\n",
        "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
        "logit_maxes = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# PyTorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2cpnypJSzqM",
        "outputId": "86018dc2-6bb4-4b2e-cc8b-7f95b3c32f74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3378, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q8SnsT4aWtm",
        "outputId": "e9752142-db7b-46d6-c201-bb46e8002c05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
              "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K4Pv5mN-arb5",
        "outputId": "66dfc66a-0c1d-41e7-c73a-47f6832fcc3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6243, -2.4272, -3.9326, -3.0437, -3.9910, -2.5102, -3.6711, -3.3064,\n",
              "         -4.0604, -3.3960, -3.2875, -3.2504, -3.2716, -3.6041, -3.4224, -4.3628,\n",
              "         -4.7433, -3.8807, -4.1414, -2.8956, -2.9827, -3.7114, -3.6110, -2.7291,\n",
              "         -2.8693, -3.5904, -3.8866],\n",
              "        [-2.8143, -2.8773, -2.3844, -2.9521, -3.3732, -3.3491, -3.9144, -3.0519,\n",
              "         -3.9707, -3.6425, -3.0702, -3.0263, -3.0289, -3.5845, -3.1193, -3.3982,\n",
              "         -3.5679, -4.0590, -3.8763, -3.3197, -3.9154, -3.6202, -4.1529, -2.7958,\n",
              "         -3.8006, -3.2692, -3.7805],\n",
              "        [-3.8690, -3.7325, -4.1361, -4.3629, -3.8186, -3.1324, -2.7301, -2.7434,\n",
              "         -2.8850, -3.4244, -3.8443, -3.3003, -3.1144, -3.0451, -3.8552, -3.6331,\n",
              "         -4.2976, -3.3922, -3.5851, -2.2865, -2.7390, -3.2471, -3.1220, -3.2976,\n",
              "         -3.3167, -3.8868, -3.6085],\n",
              "        [-3.3875, -3.6447, -3.2172, -3.0124, -2.8729, -3.4839, -2.9755, -3.2208,\n",
              "         -3.1067, -3.8101, -3.2562, -3.6288, -3.3350, -3.1685, -2.8321, -2.8606,\n",
              "         -3.7271, -3.5807, -4.0967, -3.0058, -3.9789, -3.5268, -3.1463, -3.8953,\n",
              "         -3.6948, -2.9660, -3.1935],\n",
              "        [-4.0702, -4.0487, -3.6273, -3.8043, -4.1385, -3.1318, -3.1595, -4.0201,\n",
              "         -3.0058, -3.1386, -3.4295, -4.1053, -3.1965, -3.7125, -3.0925, -1.8390,\n",
              "         -3.9841, -2.9492, -3.0560, -2.8342, -3.1880, -3.9435, -3.6848, -4.2674,\n",
              "         -3.1469, -3.7213, -3.1833],\n",
              "        [-3.3307, -3.3372, -2.9517, -2.8201, -2.7986, -3.5570, -3.3921, -2.9173,\n",
              "         -3.6619, -4.0055, -3.1284, -4.0008, -3.5542, -3.1535, -2.7655, -3.0805,\n",
              "         -4.0902, -3.7479, -4.5627, -3.5471, -3.4518, -3.3536, -3.0914, -4.0170,\n",
              "         -4.0566, -2.4763, -3.1574],\n",
              "        [-2.8233, -4.4087, -2.7378, -4.2566, -3.5708, -3.8694, -2.7053, -2.9646,\n",
              "         -3.0411, -3.0181, -3.9965, -3.2831, -3.5375, -4.0718, -4.1232, -2.7996,\n",
              "         -2.5655, -3.0735, -4.5575, -3.5100, -3.6090, -2.8716, -2.9869, -3.8924,\n",
              "         -3.3207, -3.6578, -3.6342],\n",
              "        [-3.0167, -3.4284, -3.7262, -2.2110, -3.6524, -2.8643, -3.3724, -2.5114,\n",
              "         -3.3165, -4.6371, -3.5776, -4.1406, -3.9283, -2.9345, -4.0127, -4.3097,\n",
              "         -4.2470, -4.2454, -4.1712, -2.4677, -3.4268, -2.9639, -3.5597, -3.3644,\n",
              "         -3.7185, -2.8200, -3.4276],\n",
              "        [-3.0081, -3.5130, -3.9733, -3.3627, -4.5843, -3.2689, -2.8347, -2.4508,\n",
              "         -3.6391, -3.8397, -3.4443, -3.4230, -3.3163, -3.7488, -4.4527, -3.9677,\n",
              "         -3.9342, -3.1969, -3.8032, -2.4774, -3.3529, -2.3832, -3.1164, -3.1430,\n",
              "         -3.1456, -4.1183, -3.4840],\n",
              "        [-3.5488, -4.2172, -3.5227, -4.0490, -3.5325, -3.3911, -3.2835, -3.4646,\n",
              "         -2.4305, -2.6945, -4.3064, -3.2524, -3.1541, -3.1996, -3.7956, -3.6214,\n",
              "         -2.8081, -3.0458, -3.1688, -3.7945, -2.7190, -3.5563, -2.6647, -3.9968,\n",
              "         -3.5377, -3.3182, -4.0598],\n",
              "        [-4.1141, -4.8744, -3.2372, -3.1777, -3.4342, -3.2738, -3.9096, -5.0284,\n",
              "         -3.4039, -2.9876, -3.6466, -3.9488, -2.8062, -3.5099, -3.2031, -1.9740,\n",
              "         -2.9435, -2.8785, -2.5463, -3.4283, -3.1240, -4.5244, -4.3174, -3.8339,\n",
              "         -3.2623, -3.5616, -3.7599],\n",
              "        [-3.7878, -3.4930, -3.7474, -1.6917, -4.4741, -2.9348, -2.5958, -3.0912,\n",
              "         -3.2385, -3.3660, -4.2165, -3.9765, -3.8920, -3.5695, -5.0007, -5.0149,\n",
              "         -3.8928, -3.2883, -4.2170, -2.8724, -2.9631, -3.1177, -3.9405, -3.3423,\n",
              "         -3.1387, -3.0558, -4.1838],\n",
              "        [-3.8871, -4.2172, -3.0962, -4.2870, -3.6803, -4.0571, -2.4094, -3.2773,\n",
              "         -2.9079, -2.8780, -4.0657, -3.1890, -3.2113, -3.6208, -4.2377, -3.2535,\n",
              "         -2.6187, -3.0387, -3.1603, -3.8398, -3.1408, -3.2228, -2.3292, -4.5883,\n",
              "         -3.8398, -3.7048, -3.6936],\n",
              "        [-3.7468, -3.6081, -2.9349, -3.9454, -4.1594, -2.6721, -3.4774, -4.1508,\n",
              "         -3.6050, -2.8861, -3.5462, -3.4100, -2.6810, -3.3330, -3.0031, -3.1053,\n",
              "         -3.5610, -3.2677, -2.5347, -4.2835, -2.7292, -4.0492, -4.0088, -3.4496,\n",
              "         -3.4037, -3.2138, -3.3155],\n",
              "        [-3.0284, -3.6913, -3.5489, -3.0298, -4.1775, -3.3701, -3.4143, -2.8154,\n",
              "         -2.9810, -2.9148, -3.4692, -3.0702, -3.0500, -3.3043, -3.6293, -3.8160,\n",
              "         -3.8549, -2.8274, -3.5733, -3.0632, -2.9437, -2.8209, -3.6213, -3.4351,\n",
              "         -3.8433, -3.8491, -3.7775],\n",
              "        [-3.0799, -2.8332, -3.4342, -4.0370, -3.9208, -2.4983, -3.5374, -3.7188,\n",
              "         -3.5843, -2.8827, -3.3561, -3.0093, -2.7391, -4.1258, -3.5376, -4.2001,\n",
              "         -3.2173, -3.8728, -2.8577, -4.0514, -3.3118, -3.5352, -3.3237, -2.7965,\n",
              "         -2.9974, -3.5104, -3.9630],\n",
              "        [-3.5341, -3.7252, -2.4883, -3.0897, -2.9002, -2.9244, -4.0316, -3.6343,\n",
              "         -4.0207, -3.8333, -2.9811, -3.8255, -3.1537, -2.8857, -2.7113, -2.8529,\n",
              "         -4.2337, -3.9564, -3.7793, -3.1014, -3.5605, -3.9155, -4.6092, -3.0527,\n",
              "         -3.8084, -3.0104, -2.9551],\n",
              "        [-2.9947, -2.4879, -3.0312, -2.9589, -3.2702, -3.2999, -3.7265, -2.5758,\n",
              "         -3.7308, -4.0138, -2.6722, -4.1831, -3.7078, -3.9360, -3.1727, -3.6608,\n",
              "         -4.2432, -3.5024, -4.1275, -2.9635, -3.9334, -3.0064, -3.5529, -3.9253,\n",
              "         -3.7357, -3.1432, -2.8655],\n",
              "        [-3.8871, -4.2172, -3.0962, -4.2870, -3.6803, -4.0571, -2.4094, -3.2773,\n",
              "         -2.9079, -2.8780, -4.0657, -3.1890, -3.2113, -3.6208, -4.2377, -3.2535,\n",
              "         -2.6187, -3.0387, -3.1603, -3.8398, -3.1408, -3.2228, -2.3292, -4.5883,\n",
              "         -3.8398, -3.7048, -3.6936],\n",
              "        [-3.7141, -3.7930, -3.3710, -4.1468, -3.3566, -3.3581, -2.5869, -2.9433,\n",
              "         -3.3977, -3.3302, -3.4725, -3.0465, -2.8550, -3.0312, -4.3218, -3.7306,\n",
              "         -3.5665, -3.8485, -3.4827, -2.4836, -3.0306, -3.2871, -3.1693, -3.0849,\n",
              "         -3.4549, -3.7975, -3.7598],\n",
              "        [-2.8406, -4.2537, -4.0171, -3.2698, -3.5645, -3.2878, -3.4063, -3.2226,\n",
              "         -3.0221, -3.7815, -2.7306, -3.2810, -2.7955, -3.8167, -3.1917, -2.6943,\n",
              "         -4.0557, -3.8355, -3.3301, -2.9634, -3.9328, -3.2761, -3.6122, -3.7237,\n",
              "         -3.3677, -2.7834, -3.3372],\n",
              "        [-2.8472, -2.6221, -2.9828, -3.0476, -3.7462, -2.7710, -3.4249, -3.0724,\n",
              "         -3.8791, -3.9408, -2.9880, -3.5617, -3.7293, -3.4723, -3.2110, -3.2116,\n",
              "         -3.9830, -3.2420, -3.9352, -2.4598, -4.3587, -3.3066, -4.1498, -3.5688,\n",
              "         -3.4276, -3.4742, -3.4404],\n",
              "        [-3.8871, -4.2172, -3.0962, -4.2870, -3.6803, -4.0571, -2.4094, -3.2773,\n",
              "         -2.9079, -2.8780, -4.0657, -3.1890, -3.2113, -3.6208, -4.2377, -3.2535,\n",
              "         -2.6187, -3.0387, -3.1603, -3.8398, -3.1408, -3.2228, -2.3292, -4.5883,\n",
              "         -3.8398, -3.7048, -3.6936],\n",
              "        [-2.9749, -4.0096, -3.7663, -4.4229, -2.9850, -3.7435, -2.6176, -3.4456,\n",
              "         -3.7366, -3.1114, -3.4450, -3.1651, -3.3200, -3.4466, -3.3634, -3.1521,\n",
              "         -2.6556, -3.6997, -3.3260, -4.1967, -3.9925, -3.7033, -2.0669, -4.1025,\n",
              "         -3.0133, -3.4630, -4.1303],\n",
              "        [-3.3660, -2.4884, -3.7141, -3.1171, -3.6307, -2.7154, -3.6414, -3.4515,\n",
              "         -3.6752, -3.5091, -2.3304, -4.0342, -3.4759, -4.4168, -3.3234, -4.0829,\n",
              "         -4.0545, -4.1668, -4.4280, -3.5914, -4.2863, -3.5260, -4.3624, -1.9115,\n",
              "         -3.0651, -3.5812, -3.0697],\n",
              "        [-2.6359, -3.5900, -4.2531, -3.9950, -3.4801, -2.5689, -3.1151, -3.3954,\n",
              "         -3.6569, -3.3008, -3.4910, -2.9080, -2.9571, -3.3756, -3.8866, -4.3934,\n",
              "         -3.3993, -3.9008, -2.8693, -4.4149, -3.7284, -3.7205, -2.5526, -3.0144,\n",
              "         -2.7412, -3.1195, -4.6362],\n",
              "        [-3.0573, -3.6723, -3.9194, -4.6127, -3.1627, -3.8590, -2.4168, -3.2263,\n",
              "         -3.6339, -2.8672, -4.0247, -2.9471, -2.8717, -3.5979, -3.7038, -4.0809,\n",
              "         -2.8944, -3.5899, -3.4659, -3.4856, -3.8300, -3.3094, -2.0102, -4.0454,\n",
              "         -3.3262, -3.6328, -4.6622],\n",
              "        [-3.6629, -3.5941, -3.0897, -3.9514, -3.4716, -3.7363, -3.1552, -3.5537,\n",
              "         -3.2970, -2.8311, -3.8603, -3.5797, -3.1700, -3.3408, -3.1191, -2.8483,\n",
              "         -3.0899, -2.9846, -3.0121, -4.1210, -2.3599, -4.0681, -3.0217, -4.4809,\n",
              "         -4.0905, -3.3148, -3.0929],\n",
              "        [-2.6675, -3.2242, -4.1435, -3.9446, -3.4614, -2.8617, -3.0360, -3.2033,\n",
              "         -4.6822, -3.5311, -3.1415, -3.4572, -3.7065, -3.8800, -3.5987, -3.5173,\n",
              "         -2.6317, -3.6245, -2.7682, -3.7318, -3.4732, -3.3162, -3.0394, -2.8791,\n",
              "         -2.5777, -4.3923, -4.0283],\n",
              "        [-3.7912, -4.0369, -3.5050, -3.5292, -3.0789, -3.8255, -2.5259, -3.4388,\n",
              "         -2.7267, -3.3062, -3.5469, -3.2757, -3.4099, -3.2954, -3.4502, -2.8383,\n",
              "         -3.5198, -3.5122, -3.3288, -3.6003, -3.1617, -3.4647, -2.7494, -4.3000,\n",
              "         -3.5147, -2.9240, -3.3751],\n",
              "        [-3.2067, -3.0292, -3.7326, -2.8209, -3.1080, -2.9500, -3.2680, -3.5225,\n",
              "         -3.7172, -3.8114, -3.3037, -3.7752, -4.1150, -3.6952, -4.4683, -3.4264,\n",
              "         -3.3961, -3.4372, -3.1154, -2.9810, -2.8922, -3.4576, -3.8482, -2.6103,\n",
              "         -2.4742, -3.8521, -3.7388],\n",
              "        [-3.0223, -3.7708, -2.7480, -4.0782, -2.6824, -3.5507, -4.0418, -3.7360,\n",
              "         -4.1637, -2.8458, -3.6352, -3.4253, -3.3429, -2.5676, -3.2330, -3.2929,\n",
              "         -3.0077, -3.0893, -3.1283, -4.3770, -2.8906, -4.4093, -2.6558, -3.8421,\n",
              "         -3.9567, -3.2292, -4.0086]], grad_fn=<LogBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs[range(n), Yb]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1SANUm4Z7AM",
        "outputId": "dbb9c9b3-565f-4fb5-f63e-6a5b2601f1ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-4.0604, -3.1193, -3.6331, -3.1463, -4.0702, -3.5471, -3.0181, -4.0127,\n",
              "        -3.2689, -4.2172, -3.1240, -1.6917, -2.9079, -3.0031, -3.0500, -3.0799,\n",
              "        -3.8255, -2.9947, -3.6936, -3.3302, -2.7834, -2.8472, -4.2172, -4.0096,\n",
              "        -3.4515, -2.8693, -2.8672, -3.9514, -2.8617, -3.3062, -3.2067, -3.1283],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss = -1/3*a -1/3*b -1/3*c (for 3 characters)\n",
        "# dloss/da = -1/3\n",
        "# dloss/da = -1/n (more generally)"
      ],
      "metadata": {
        "id": "_K2FQMC3a0si"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts.shape, counts_sum_inv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Mx7jjIeBmR",
        "outputId": "93a434a9-ed8d-4d3f-eee6-f68dece5be09"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c = a * b, but with tensors:\n",
        "# a[3,3] * b[3,1] --->\n",
        "# a11*b1 a12*b1 a13*b1\n",
        "# a21*b2 a22*b2 a23*b2\n",
        "# a31*b3 a32*b3 a33*b3\n",
        "# c[3,3]\n"
      ],
      "metadata": {
        "id": "F1qgX_nzeF42"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts.shape, counts_sum.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CHDPM8FfKb_",
        "outputId": "9d64d04d-de21-4b74-8a2b-02ea4872a80b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a11 a12 a13 ---> b1 (= a11 + a12 + a13)\n",
        "# a21 a22 a23 ---> b2 (= a21 + a22 + a23)\n",
        "# a31 a32 a33 ---> b3 (= a31 + a32 + a33)"
      ],
      "metadata": {
        "id": "JrYZkIT4gYtW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_logits.shape, logits.shape, logit_maxes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeQOMJsuiQV0",
        "outputId": "08c02832-fd73-44ba-9524-3e0a5b0aba53"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c11 c12 c13 = a11 a12 a13     b1\n",
        "# c21 c22 c23 = a21 a22 a23  -  b2\n",
        "# c31 c32 c33 = a31 a32 a33     b3\n",
        "\n",
        "# so e.g. c32 = a32 - b3"
      ],
      "metadata": {
        "id": "JIeSdZETid3c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dlogit_maxes # the gradient of logit_maxes is intutively 0"
      ],
      "metadata": {
        "id": "3TeJHGZTj-YI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9SPZbgb5lIkZ",
        "outputId": "53836d9b-26e3-4d46-b15c-5d7144974eb6",
        "collapsed": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b00d5bc5e10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(1, keepdim=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LWR7DVMJkSYA",
        "outputId": "4eb210e1-34ed-413c-ce82-9ffe01f7cd24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([[0.9918],\n",
              "        [0.7969],\n",
              "        [1.0879],\n",
              "        [0.4565],\n",
              "        [1.5636],\n",
              "        [0.9086],\n",
              "        [0.7110],\n",
              "        [1.3253],\n",
              "        [1.0712],\n",
              "        [0.9779],\n",
              "        [1.6448],\n",
              "        [1.9672],\n",
              "        [1.0797],\n",
              "        [0.8068],\n",
              "        [0.5617],\n",
              "        [0.7482],\n",
              "        [0.8727],\n",
              "        [0.7880],\n",
              "        [1.0797],\n",
              "        [0.7865],\n",
              "        [0.6464],\n",
              "        [0.9341],\n",
              "        [1.0797],\n",
              "        [1.3094],\n",
              "        [1.4491],\n",
              "        [0.9006],\n",
              "        [1.2623],\n",
              "        [0.9493],\n",
              "        [0.8552],\n",
              "        [0.8359],\n",
              "        [1.0787],\n",
              "        [0.8091]], grad_fn=<MaxBackward0>),\n",
              "indices=tensor([[ 1],\n",
              "        [ 2],\n",
              "        [19],\n",
              "        [14],\n",
              "        [15],\n",
              "        [25],\n",
              "        [16],\n",
              "        [ 3],\n",
              "        [21],\n",
              "        [ 8],\n",
              "        [15],\n",
              "        [ 3],\n",
              "        [22],\n",
              "        [18],\n",
              "        [ 7],\n",
              "        [ 5],\n",
              "        [ 2],\n",
              "        [ 1],\n",
              "        [22],\n",
              "        [19],\n",
              "        [15],\n",
              "        [19],\n",
              "        [22],\n",
              "        [22],\n",
              "        [23],\n",
              "        [22],\n",
              "        [22],\n",
              "        [20],\n",
              "        [24],\n",
              "        [ 6],\n",
              "        [24],\n",
              "        [13]]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits.shape, h.shape, W2.shape, b2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLS81x8ClojN",
        "outputId": "b8540d19-b5c4-4289-960e-b83606937b99"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([64, 27]),\n",
              " torch.Size([27]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we check out the shapes\n",
        "# there is only one way that we can make dh = some combination of logits and W2\n",
        "dh = dlogits @ W2.T\n",
        "#32x64 = 32x27 @ (64x27).T\n",
        "dW2 = h.T @ dlogits\n",
        "#64x27 = (32x63).T @ 32x27\n",
        "db2 = dlogits.sum(0)"
      ],
      "metadata": {
        "id": "_BiKDwVTOAv2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqlEybdPQ9ze",
        "outputId": "f90c3dfe-48b0-45b2-f250-123736cc4b0e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]),\n",
              " torch.Size([1, 64]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "dbnraw = bngain * dhpreact\n",
        "dbnbias = dhpreact.sum(0, keepdim=True)"
      ],
      "metadata": {
        "id": "mFUhnRcfRRbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnraw.shape, bndiff.shape, bnvar_inv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbR37uQvTSju",
        "outputId": "2f913847-1aa3-48d2-930e-b8cb96756fc5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff = bnvar_inv * dbnraw\n",
        "dbnvar_inv = (dbndiff * dbnraw).sum(0, keepdim=True)\n"
      ],
      "metadata": {
        "id": "589ur4lLTaTC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv"
      ],
      "metadata": {
        "id": "dcul24mAVcWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnvar.shape, bndiff.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhvirxg8XB3H",
        "outputId": "55e30b58-1e38-4b61-9664-58842acee1af"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 64]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a11 a12\n",
        "# a21 a22\n",
        "# --->\n",
        "# b1  b2, where:\n",
        "# b1 = 1/(n-1)*(a11 + a21)\n",
        "# b2 = 1/(n-1)*(a12 + a22)"
      ],
      "metadata": {
        "id": "18N2ES9uXlB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar"
      ],
      "metadata": {
        "id": "nKIR5V_lYrKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff += (2 * bndiff) * dbndiff2"
      ],
      "metadata": {
        "id": "MPw3W97tZOuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bndiff.shape, hprebn.shape, bnmeani.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05AvivXTb52E",
        "outputId": "04f32a3a-e337-409e-da09-a02c562d28a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn = dbndiff.clone()\n",
        "#dbnmeani = (-torch.ones_like(bndiff) * dbndiff).sum(0)\n",
        "dbnmeani = (-dbndiff).sum(0)"
      ],
      "metadata": {
        "id": "n1VkL6YTb-2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bndiff.shape, hprebn.shape, bnmeani.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNe7UKCTc79t",
        "outputId": "1fa1efb1-dc85-4b4b-b8d9-eb3eca38f0c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn = 1.0/n * (torch.ones_like(hprebn) * dbnmeani)"
      ],
      "metadata": {
        "id": "LlCs8brLdFQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass: hprebn = embcat @ W1 + b1\n",
        "hprebn.shape, embcat.shape, W1.shape, b1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8ZlszT-dzXQ",
        "outputId": "5e4692b5-e0b7-42c3-95e9-3f27fa55b754"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]),\n",
              " torch.Size([32, 30]),\n",
              " torch.Size([30, 64]),\n",
              " torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dembcat = dhprebn @ W1.T\n",
        "dW1 = embcat.T @ dhprebn\n",
        "db1 = dhprebn.sum(0)"
      ],
      "metadata": {
        "id": "iCQw7F8KfgbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass: embcat = emb.view(emb.shape[0], -1)\n",
        "embcat.shape, emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHr6hQEKgxAr",
        "outputId": "1ff28e64-0a52-4a44-990d-fdc29c26aef0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demb = dembcat.view(emb.shape)"
      ],
      "metadata": {
        "id": "k-cO5poBhM98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass: emb = C[Xb]\n",
        "print(emb.shape, C.shape, Xb.shape)\n",
        "print(Xb[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m80ga8I2hj_d",
        "outputId": "76ee3011-72b1-46b3-fa5c-8fffa0d74616"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 10]) torch.Size([27, 10]) torch.Size([32, 3])\n",
            "tensor([[ 1,  1,  4],\n",
            "        [18, 14,  1],\n",
            "        [11,  5,  9],\n",
            "        [ 0,  0,  1],\n",
            "        [12, 15, 14]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dC = torch.zeros_like(C)\n",
        "\n",
        "for k in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    ix = Xb[k, j]\n",
        "    dC[ix] += demb[k, j]"
      ],
      "metadata": {
        "id": "yTtzHDG1iMyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: backprop through the whole thing manually\n",
        "# backpropagating through exactly all of the variable\n",
        "# as they are defined in the forward pass above, one by one\n",
        "\n",
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1.0/n\n",
        "\n",
        "dprobs = (1.0 / probs) * dlogprobs # this line is taking the examples that have a very low probability currently assigned and boosting their gradient\n",
        "\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "\n",
        "#dnorm_logits = (norm_logits.exp()) * dcounts\n",
        "dnorm_logits = counts * dcounts\n",
        "dlogits = dnorm_logits.clone()\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
        "\n",
        "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
        "\n",
        "dh = dlogits @ W2.T\n",
        "dW2 = h.T @ dlogits\n",
        "db2 = dlogits.sum(0)\n",
        "\n",
        "dhpreact = (1.0 - h**2) * dh\n",
        "\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "dbnraw = bngain * dhpreact\n",
        "dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "\n",
        "dbndiff = bnvar_inv * dbnraw\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "\n",
        "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
        "dbndiff += (2 * bndiff) * dbndiff2\n",
        "\n",
        "dhprebn = dbndiff.clone()\n",
        "dbnmeani = (-dbndiff).sum(0)\n",
        "\n",
        "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "dembcat = dhprebn @ W1.T\n",
        "dW1 = embcat.T @ dhprebn\n",
        "db1 = dhprebn.sum(0)\n",
        "\n",
        "demb = dembcat.view(emb.shape)\n",
        "\n",
        "dC = torch.zeros_like(C)\n",
        "\n",
        "for k in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    ix = Xb[k, j]\n",
        "    dC[ix] += demb[k, j]\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "cmp('logits', dlogits, logits)\n",
        "cmp('h', dh, h)\n",
        "cmp('W2', dW2, W2)\n",
        "cmp('b2', db2, b2)\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "cmp('bngain', dbngain, bngain)\n",
        "cmp('bnbias', dbnbias, bnbias)\n",
        "cmp('bnraw', dbnraw, bnraw)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "cmp('bnvar', dbnvar, bnvar)\n",
        "cmp('dbndiff2', dbndiff2, bndiff2)\n",
        "cmp('bndiff', bndiff, bndiff)\n",
        "cmp('bnmeani', dbnmeani, bnmeani)\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "cmp('embcat', dembcat, embcat)\n",
        "cmp('W1', dW1, W1)\n",
        "cmp('b1', db1, b1)\n",
        "cmp('emb', demb, emb)\n",
        "cmp('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU6pRMu2X2QF",
        "outputId": "ee9534c8-8f84-4143-be1b-7904ba24f317"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnraw           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnvar           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
            "dbndiff2        | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
            "bndiff          | exact: False | approximate: False | maxdiff: 5.253848075866699\n",
            "bnmeani         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 5.820766091346741e-10\n",
            "embcat          | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "W1              | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n",
            "b1              | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
            "emb             | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "C               | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2: backprop through cross_entropy but all in one go\n",
        "# to complete this challange look at the mathematical expression of the loss,\n",
        "# take the derivative, simplify the expression, and just write it out\n",
        "\n",
        "# Forward pass:\n",
        "\n",
        "# BEFORE:\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum ** -1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# NOW:\n",
        "loss_fast = F.cross_entropy(logits, Yb)\n",
        "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())\n"
      ],
      "metadata": {
        "id": "h9BBVzA1bvxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13cea59b-1052-4085-c504-126b575a6af7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3377785682678223 diff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Pass\n",
        "\n",
        "dlogits = F.softmax(logits, 1)\n",
        "dlogits[range(n), Yb] -= 1\n",
        "dlogits /= n\n",
        "\n",
        "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exli3n4IlMnh",
        "outputId": "c1194d07-56dc-4791-df79-5a258415ab74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits          | exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape, Yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSRJ9dDGpf3-",
        "outputId": "7774d580-5a11-4f59-9256-5764a6d10645"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(logits, 1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ol5N4X1pioV",
        "outputId": "6beac69e-d3b5-4da1-b5d3-65a735e31210"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0680, 0.0928, 0.0195, 0.0515, 0.0181, 0.0781, 0.0264, 0.0350, 0.0184,\n",
              "        0.0298, 0.0428, 0.0353, 0.0368, 0.0278, 0.0364, 0.0136, 0.0098, 0.0214,\n",
              "        0.0159, 0.0553, 0.0441, 0.0236, 0.0263, 0.0690, 0.0573, 0.0243, 0.0228],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0] * n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgQpZgUvpEvq",
        "outputId": "eae75dbc-6598-4764-84ed-ca8050674d7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0680,  0.0928,  0.0195,  0.0515,  0.0181,  0.0781,  0.0264,  0.0350,\n",
              "        -0.9816,  0.0298,  0.0428,  0.0353,  0.0368,  0.0278,  0.0364,  0.0136,\n",
              "         0.0098,  0.0214,  0.0159,  0.0553,  0.0441,  0.0236,  0.0263,  0.0690,\n",
              "         0.0573,  0.0243,  0.0228], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uki8A6Y4px6Q",
        "outputId": "24b8e255-476e-465e-de9a-6e4c4c1c4f20"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-5.5879e-09, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(dlogits.detach(), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "3OxRv3w6pNaR",
        "outputId": "75667708-b90b-42d9-8e91-9946c40b0c71"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x787fb2043110>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAKTCAYAAADlpSlWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMTdJREFUeJzt3X+M3HWdP/DX7OzubEu3iwX6y7ZYQIry6xKU2qAcJz1KTYhITfBHcmAIRq+Qg8bT9KIinknvMFHPbxD/uYMzsepxEYxcDqNVSswV1BqCKNa2gJQrLdCzu23398x8/+ix50oX2O6rzPLu45FM0p2dPvc1n/l8PvPcz8x+ptJsNpsBAFCItlYPAACQSbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCU9lYP8KcajUbs3r07uru7o1KptHocAGAaaDabceDAgVi4cGG0tb38sZlpV252794dixcvbvUYAMA0tGvXrli0aNHL3mbalZvu7u6IiPjlL3859u+p6OjomHLGi3p7e9OyIiJqtVpa1uDgYFrW7Nmz07IiIg4ePJiW9UptfTLOOeectKxf/epXaVkREdVqNS2r0WikZWXKnitz3RgZGUnLyjwJfOZ6EZE724wZM9Ky6vV6Wtbo6GhaVraZM2emZWUus6GhobSsiLz17ODBg3HRRRe9qm4w7crNiy9FdXd3p5Sbzs7OKWe8KHtnnFluMktcxnL/Y5kvL2Y+gWXKXmbKzeQpN5On3LTWdC03mc+bEbnrWcSre06Zns8UAABHSbkBAIqi3AAARTlm5eb222+PN73pTdHV1RXLly+Pn/3sZ8fqRwEAjDkm5eY73/lOrFu3Lm655Zb45S9/Geeff36sWrUqnnvuuWPx4wAAxhyTcvOlL30prr/++vjIRz4Sb33rW+PrX/96zJw5M/7lX/7lWPw4AIAx6eVmeHg4tm7dGitXrvy/H9LWFitXrowtW7a85PZDQ0PR19c37gIAcLTSy80LL7wQ9Xo95s2bN+76efPmxZ49e15y+w0bNkRPT8/YxdmJAYCpaPlfS61fvz56e3vHLrt27Wr1SADA61j6GYpPPvnkqFarsXfv3nHX7927N+bPn/+S29dqtdQz9QIAx7f0IzednZ1xwQUXxKZNm8auazQasWnTplixYkX2jwMAGOeYfLbUunXr4pprrom3ve1tceGFF8ZXvvKVOHToUHzkIx85Fj8OAGDMMSk3V199dTz//PPx2c9+Nvbs2RN/9md/Fvfff/9L3mQMAJDtmH0q+A033BA33HDDsYoHADiilv+1FABAJuUGACjKMXtZaqrq9XrU6/Up5wwNDSVMc9js2bPTsiIOn805S3t73kPZ39+flhUR0Ww207La2vL6+BNPPJGWlXkfIyKq1Wpq3nSUvcyWLVuWlrVt27a0rEajMS2zIiIqlUpa1sjISFpWxr7/WMlcbzMfz8HBwbSszOeTiLzHczLrqyM3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjtrR5gIkNDQ9HZ2dnqMcbp7+9v9QgTqlQqaVnt7bmrRVdXV1rWdL2fg4ODaVnZeW1teb/DVKvVtKyOjo60rIiI3/zmN2lZS5cuTcvavn17Wlb2ttloNNKy5syZk5Z18ODBtKyRkZG0rGyZs2Vum6Ojo2lZEXmzTWZf5sgNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAUpb3VA0ykWq1GtVqdck6j0UiY5rD29tzFlXH/joWRkZHUvHq9npbVbDbTsiqVSlpW5lwRER0dHWlZmcs/MyvbzJkz07L++7//Oy1rcHAwLStzf5adt3///rSs4eHhtKzM7TwiYtmyZWlZ27ZtS8vKvJ+Z+59MbW2v/niMIzcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKO2tHmAi55xzTkrOzp07U3KOhXq9npbVaDTSsjo6OtKyInJnGx0dTcvq6upKy2pvz92Ums1mWlbmepa5bmQ+lhERbW15v6stXLgwLeuJJ55Iy+rs7EzLylatVtOyMtezkZGRtKyIiG3btqVlZe4ba7VaWlb2Mst+Tnk1HLkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARWlv9QAT+fWvfx3d3d1Tzmk2mwnTHNbenru4qtVqWlbm/RwcHEzLiohoa8vr0F1dXWlZw8PDaVmNRiMtKyKis7MzLatSqaRl1ev1tKzs7Skz75lnnknLyjQyMpKal7neLlu2LC1r586daVmZ+5+I3PUscx+UmZXx3PvHhoaGUvNeDUduAICiKDcAQFGUGwCgKMoNAFAU5QYAKEp6ufnc5z4XlUpl3OWss87K/jEAAEd0TP4U/Oyzz44f/ehH//dDkv/kEwBgIsekdbS3t8f8+fOPRTQAwMs6Ju+52b59eyxcuDBOO+20+PCHPxxPP/30hLcdGhqKvr6+cRcAgKOVXm6WL18ed911V9x///1xxx13xJNPPhnvete74sCBA0e8/YYNG6Knp2fssnjx4uyRAIDjSKWZed7+I9i/f3+ceuqp8aUvfSmuu+66l3x/aGho3KmZ+/r6YvHixT5+YZKOl49fmK6nPp/OH7+Qecr+zI9yyN6eMpfZdD0tfubyjzg+Pn4h+yluuu6DMk3Xj184cOBAvPWtb43e3t6YPXv2y972mL/T98QTT4wzzzwzduzYccTv12q1qNVqx3oMAOA4cczPc3Pw4MHYuXNnLFiw4Fj/KACA/HLziU98IjZv3hxPPfVU/Nd//Ve8733vi2q1Gh/84AezfxQAwEukvyz1zDPPxAc/+MHYt29fnHLKKfHOd74zHnrooTjllFOyfxQAwEukl5tvf/vb2ZEAAK+az5YCAIqi3AAARZm2H/rU3t6ecj6B/v7+hGkO6+rqSsuKOPyXZFmm6zlzInLPPzJdz1t02mmnpWVFRGzbti0ta7quG5nn34nIPWfICSeckJaVud8YGBhIy4rIXWbT9dw02acaqdfraVmZ5y3K3M4PHTqUlhWRdz8ns+wduQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKK0t3qAiYyOjsbo6OiUc9rb8+7ioUOH0rIiIubOnZuW9cILL6RldXR0pGVFRAwNDaVlzZo1Ky2rv78/Les3v/lNWlZERFtb3u8dGdvRsTBz5szUvAULFqRl7dy5My0rU7PZbPUIE+ru7k7LOnDgQFpW9jLL3J6q1WpaVqPRSMvq7OxMy4rIW2aVSuVV39aRGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCU9lYPMJFKpRKVSqXVY4zTbDZT8/7whz+kZdXr9bSsM888My0rIuL3v/99al6WRqORllWtVtOysmXOlrlNDgwMpGVFROzYsSM1L0vmMuvo6EjLiogYHR1Ny8q8n5lZM2bMSMuKyN3XTtdlNjg4mJYVEdHe/tpXDUduAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFHaWz3AROr1etTr9SnnvOlNb5r6MP/rqaeeSsuKiBgdHU3LqlaraVk7duxIy4qIGBkZScsaHh5Oy5o9e3Za1sDAQFpWRMTg4GBaVkdHR1pWpvb23N1Pxv7iRZVKJS2rq6srLStzW4rIXTd6e3vTsmbMmJGWlTlXREStVkvLytzO29ryjlVkb5uNRuM1z3HkBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABSlvdUDTKRer0e9Xp9yzvbt2xOmOaxSqaRlRUR0dHSkZWUsq2Mlc7bMrIMHD6ZlZa8bbW15v3eMjo6mZXV1daVlDQ8Pp2VFRLS35+3OTjnllLSs559/Pi2rWq2mZUXk7oMGBgbSsk499dS0rF//+tdpWRER/f39aVmZ23nmPqjRaKRltYojNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAijLpcvPggw/GFVdcEQsXLoxKpRL33nvvuO83m8347Gc/GwsWLIgZM2bEypUrU/8cGwDg5Uy63Bw6dCjOP//8uP3224/4/dtuuy2++tWvxte//vV4+OGH44QTTohVq1bF4ODglIcFAHglkz7r1erVq2P16tVH/F6z2YyvfOUr8elPfzre+973RkTEN77xjZg3b17ce++98YEPfOAl/2doaCiGhobGvu7r65vsSAAAY1Lfc/Pkk0/Gnj17YuXKlWPX9fT0xPLly2PLli1H/D8bNmyInp6escvixYszRwIAjjOp5WbPnj0RETFv3rxx18+bN2/se39q/fr10dvbO3bZtWtX5kgAwHGm5Z8tVavVolartXoMAKAQqUdu5s+fHxERe/fuHXf93r17x74HAHAspZabpUuXxvz582PTpk1j1/X19cXDDz8cK1asyPxRAABHNOmXpQ4ePBg7duwY+/rJJ5+MRx55JObMmRNLliyJm266Kb7whS/Em9/85li6dGl85jOfiYULF8aVV16ZOTcAwBFNutz84he/iL/4i78Y+3rdunUREXHNNdfEXXfdFZ/85Cfj0KFD8dGPfjT2798f73znO+P++++Prq6uvKkBACYw6XJzySWXRLPZnPD7lUolPv/5z8fnP//5KQ0GAHA0fLYUAFAU5QYAKErLz3Mzkba2tmhrm3r3qlarCdMcVq/X07IiIlatWpWWdd9996VlzZw5My0rIlLPYzQyMpKW9XIvr05W9rrRaDRS87JkfkZcxvb9xzJnyzyZaOY+KHu9GBgYSMuaMWNGWtYf/9HKVGVu5xERo6OjaVmZ60bm9pS9bQ4PD6fkTGb9d+QGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFKW91QNMpNlsRrPZnHJOvV5PmOawWq2WlhUR8R//8R9pWW1teT11YGAgLSsioru7Oy0rY5140bJly9Kyfve736VlRUQ0Go20rPb26bmZZ97HiNxtoKOjIy2rq6srLWtoaCgtKyL3fmbOlrnOViqVtKyIiDe84Q1pWfv27UvLylz/s5dZtVp9zXMcuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFaW/1AMdae3veXWxry+2ClUolLavRaKRlzZo1Ky0rIuLQoUNpWZn38/HHH0/LylatVtOyMpfZzJkz07IGBwfTsiIizjrrrLSs7du3p2X19/enZWXLfDwPHDiQlpW5385e/v/zP/+TltXR0ZGW1Ww207Km63PdZPaLjtwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAorS3eoCJdHR0REdHx5RzRkdHE6Y5bHh4OC0rIqJWq6VlDQ4OTsusiIhKpZKW1dXVlZaVOVe9Xk/LylatVtOyFi9enJa1ffv2tKyIiN/+9rdpWSMjI2lZmTLX/4iI/v7+tKzOzs60rMz9duZcEbmzZWo0GtMyKyJvXzuZZe/IDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFKW91QNM5Pzzz49KpTLlnKeeemrqw/yv4eHhtKyIiKGhobSsjGX1ohNOOCEtKyLi4MGDaVmZy6ytLa/bV6vVtKyI3Mcz0+9///u0rEOHDqVlReQ+Bs1mMy2rs7MzLWtwcDAtKyKiq6srLStztszHstFopGVF5G6bmetG5v3Mfq7L2p4mk+PIDQBQFOUGACiKcgMAFEW5AQCKotwAAEWZdLl58MEH44orroiFCxdGpVKJe++9d9z3r7322qhUKuMul19+eda8AAAva9Ll5tChQ3H++efH7bffPuFtLr/88nj22WfHLt/61remNCQAwKs16fPcrF69OlavXv2yt6nVajF//vyjHgoA4Ggdk/fcPPDAAzF37txYtmxZfPzjH499+/ZNeNuhoaHo6+sbdwEAOFrp5ebyyy+Pb3zjG7Fp06b4x3/8x9i8eXOsXr066vX6EW+/YcOG6OnpGbssXrw4eyQA4DiS/vELH/jAB8b+fe6558Z5550Xp59+ejzwwANx6aWXvuT269evj3Xr1o193dfXp+AAAEftmP8p+GmnnRYnn3xy7Nix44jfr9VqMXv27HEXAICjdczLzTPPPBP79u2LBQsWHOsfBQAw+ZelDh48OO4ozJNPPhmPPPJIzJkzJ+bMmRO33nprrFmzJubPnx87d+6MT37yk3HGGWfEqlWrUgcHADiSSZebX/ziF/EXf/EXY1+/+H6Za665Ju6444549NFH41//9V9j//79sXDhwrjsssvi7//+76NWq+VNDQAwgUmXm0suuSSazeaE3//BD34wpYEAAKbCZ0sBAEVRbgCAoqSf5ybL1q1bo7u7e8o5Q0NDCdMcNmvWrLSsiIjBwcG0rGq1mpaVucwiYsITOB6Ntra8Pt5oNKZlVkSkvkdt0aJFaVm///3v07JmzJiRlhUR0d6etzsbHR1NyxoYGEjLypa5rXd0dKRlZS7/7G0zMy9zv525zDK3pYi8+zkyMvKqb+vIDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGAChKe6sHmMjb3va2qFQqU87ZvXt3wjSH9ff3p2VFRLS15XXL0dHRtKxms5mWFREpj+OLZs6cmZaV+Xg2Go20rIiIjo6OtKzt27enZWWuZ5lZEbnLLHu2LNVqNTWvXq+nZWXuzzL3QZ2dnWlZEbnrxsjISFpW5n42+zkga92YTI4jNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAo7a0eYCI///nPo7u7e8o5f/jDHxKmOaxWq6VlRUQMDg6mZbW15fXURqORlhURKY/jizKXWebjWa/X07IiIg4ePJiW1dnZmZaVKXs9Gx4eTsvq6OhIyzrhhBPSsoaGhtKyInL3G9N1+Wc78cQT07L27duXlpX5WGbvz974xjem5DSbzVd9W0duAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKO2tHuBYa2vL62+NRiMtK1vm/axUKmlZERHNZjMtq1qtpmWNjIykZZ122mlpWRERTzzxRGpelo6OjrSszPUiImJgYCAtq16vp2X19/enZWXvgzL3G7Nnz07Lms7L7MCBA2lZtVotLStznc1eZjt37kzJOXDgQJx77rmv6raO3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICitLd6gIl0dXVFV1fXlHP6+/sTpjms2WymZUVEdHR0pGU1Go20rLa23M47MDCQllWpVNKyMu/n9u3b07IiImbOnJmWlbn8M7eBwcHBtKyISNlfvKharaZlHTp0KC0rc/2PyN0GMve1w8PDaVmZj2VE7r42U+ZjefbZZ6dlRURs27YtJWcy99GRGwCgKMoNAFAU5QYAKIpyAwAURbkBAIoyqXKzYcOGePvb3x7d3d0xd+7cuPLKK1/yLujBwcFYu3ZtnHTSSTFr1qxYs2ZN7N27N3VoAICJTKrcbN68OdauXRsPPfRQ/PCHP4yRkZG47LLLxv2p48033xzf//734+67747NmzfH7t2746qrrkofHADgSCZ1npv7779/3Nd33XVXzJ07N7Zu3RoXX3xx9Pb2xj//8z/Hxo0b493vfndERNx5553xlre8JR566KF4xzvekTc5AMARTOk9N729vRERMWfOnIiI2Lp1a4yMjMTKlSvHbnPWWWfFkiVLYsuWLUfMGBoair6+vnEXAICjddTlptFoxE033RQXXXRRnHPOORERsWfPnujs7IwTTzxx3G3nzZsXe/bsOWLOhg0boqenZ+yyePHiox0JAODoy83atWvjsccei29/+9tTGmD9+vXR29s7dtm1a9eU8gCA49tRfbbUDTfcEPfdd188+OCDsWjRorHr58+fH8PDw7F///5xR2/27t0b8+fPP2JWrVaLWq12NGMAALzEpI7cNJvNuOGGG+Kee+6JH//4x7F06dJx37/ggguio6MjNm3aNHbdtm3b4umnn44VK1bkTAwA8DImdeRm7dq1sXHjxvje974X3d3dY++j6enpiRkzZkRPT09cd911sW7dupgzZ07Mnj07brzxxlixYoW/lAIAXhOTKjd33HFHRERccskl466/884749prr42IiC9/+cvR1tYWa9asiaGhoVi1alV87WtfSxkWAOCVTKrcNJvNV7xNV1dX3H777XH77bcf9VAAAEfLZ0sBAEVRbgCAohzVn4K/Fs4999yoVCpTzsk8b87Q0FBaVkREW1tetxwdHU3Lyv7T/MzlNl2X2at5yXYyRkZG0rLq9fq0zKpWq2lZEYdPLDodszL2Yy/KXmaZ20BPT09aVuY+I3P5R0zvbSDL448/npqXtX+cTI4jNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAo7a0eYCI///nPo7u7e8o5c+fOTZjmsF27dqVlRUQMDg6mZbW15fXU/v7+tKyISHkcX5S5zGq1WlpWvV5Py4rIvZ/t7dNzM280Gql5w8PDaVkdHR1pWbNmzUrLGhoaSsuKiKhUKmlZfX19aVmZ22a2OXPmpGXt27cvLSvzOSBzvcjUbDZf9W0duQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKK0t3qAidRqtajVaq0eY5zR0dHUvGazmZbV2dmZljU8PJyWFRHRaDSmZdbg4GBaVnt77qaUnZclc52tVCppWRERHR0daVnZs2UZGRlJzctczzK3zcx9UPZjWa1W07IyZ8t8vsxez7LWjcnkOHIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAitLe6gEmMjo6GqOjo1POeeGFFxKmOayvry8tKyKiVqulZQ0PD6dldXV1pWVFRPT396dlvfnNb07L2rFjR1pWvV5Py4qIOOmkk9Kynn/++bSstra834eyl1lnZ2daVub2lJmVLXO2arWalpW5bmSusxERzz33XFrWokWL0rIyt/Nms5mWFZH3XDeZ9dWRGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCU9lYPMJGurq7o6uqacs6BAwcSpjms0WikZUVEjIyMpGW1teX11Gq1mpYVEdHR0ZGW9cQTT6RlZT6emcs/IuIPf/hDWlbGdnQsjI6OTtu8ZrOZlpW5/tfr9bSsiIhzzjknLetXv/pVWlbmPijzsYyI6O7uTst6/vnn07Ky99uZBgYGXvMcR24AgKIoNwBAUZQbAKAoyg0AUBTlBgAoyqTKzYYNG+Ltb397dHd3x9y5c+PKK6+Mbdu2jbvNJZdcEpVKZdzlYx/7WOrQAAATmVS52bx5c6xduzYeeuih+OEPfxgjIyNx2WWXxaFDh8bd7vrrr49nn3127HLbbbelDg0AMJFJnefm/vvvH/f1XXfdFXPnzo2tW7fGxRdfPHb9zJkzY/78+TkTAgBMwpTec9Pb2xsREXPmzBl3/Te/+c04+eST45xzzon169dHf3//hBlDQ0PR19c37gIAcLSO+gzFjUYjbrrpprjooovGneXyQx/6UJx66qmxcOHCePTRR+NTn/pUbNu2Lb773e8eMWfDhg1x6623Hu0YAADjHHW5Wbt2bTz22GPx05/+dNz1H/3oR8f+fe6558aCBQvi0ksvjZ07d8bpp5/+kpz169fHunXrxr7u6+uLxYsXH+1YAMBx7qjKzQ033BD33XdfPPjgg7Fo0aKXve3y5csjImLHjh1HLDe1Wi1qtdrRjAEA8BKTKjfNZjNuvPHGuOeee+KBBx6IpUuXvuL/eeSRRyIiYsGCBUc1IADAZEyq3KxduzY2btwY3/ve96K7uzv27NkTERE9PT0xY8aM2LlzZ2zcuDHe8573xEknnRSPPvpo3HzzzXHxxRfHeeedd0zuAADAH5tUubnjjjsi4vCJ+v7YnXfeGddee210dnbGj370o/jKV74Shw4disWLF8eaNWvi05/+dNrAAAAvZ9IvS72cxYsXx+bNm6c0EADAVPhsKQCgKMoNAFCUoz7PzbE2PDwcw8PDU855pZfSJqOtLbcLNhqNtKz29ryH8uDBg2lZEYffcJ7lTz/HbLo488wzU/Mef/zxtKzM9TZzPcvcNiMiKpXKtMzq7OxMyxocHEzLishdzzKXWb1eT8vKXGcjImbPnp2WtXv37rSszPuZ+dzUKo7cAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUdpbPcBE6vV61Ov1Kee0teX1t2q1mpYVEbFkyZK0rKeeeiotq1KppGVFRBw8eDAtq9lspmVlPp47duxIy4qIGB0dTcvK2I5elLn8M7fNiNz1tr09b9eY+VhmzpVteHg4Launpyctq7e3Ny0rIuKFF15Iy8rcnjLXs+znulqtlpIzmXXMkRsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQlPZWDzCRWq0WtVptyjkjIyMJ0xw2PDyclhURsXPnzrSsZrOZlnX22WenZUVEbNu2LS2r0WikZWU+ntVqNS0rIqKzszMtK/N+1uv1tKzMdTYiolKppGVlrmczZ85Myzp48GBaVkTEjBkz0rJGR0fTsjLvZ3v7tH2aS103Ojo60rJ6e3vTsiLytqfJPJ87cgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCK0t7qASYyMDAQ7e1TH6/ZbCZMc1i1Wk3LioioVCppWW1teT31scceS8uKiOjo6EjLGhwcTMs64YQT0rIWLVqUlhUR8cQTT6RlZa63jUYjLSt7e8qUuc729/enZWUbHh5Oy5qu+7N6vZ6WFREpz0svGhgYSMsaGRlJy6rVamlZmSazXTpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIrS3uoBJnLBBRdEpVKZcs5TTz019WH+19DQUFpWRMSMGTPSskZHR9OyarVaWlZE/nLLMjg4mJb1u9/9Li0rIqKtLe/3jpGRkbSsZrM5LbMiIur1elpWo9FIy8rYjx0rmbN1dHSkZU3n5Z+5P5s9e3ZaVqYDBw6k5mXtzyazjTtyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKJMqN3fccUecd955MXv27Jg9e3asWLEi/vM//3Ps+4ODg7F27do46aSTYtasWbFmzZrYu3dv+tAAABOZVLlZtGhR/MM//ENs3bo1fvGLX8S73/3ueO973xu//vWvIyLi5ptvju9///tx9913x+bNm2P37t1x1VVXHZPBAQCOpNKc4pm05syZE1/84hfj/e9/f5xyyimxcePGeP/73x8REb/97W/jLW95S2zZsiXe8Y53HPH/Dw0NjTspUl9fXyxevDja29udxG8SMk/il3kCuYjc2abrSeQyTzoWEdHZ2ZmWNV1P4pe9nmWexK+9Pe/8ppknkctezzLvZ+bjmXk/M9eLiNzZuru707IyTdeT+B04cCDOPffc6O3tfcUTIB71T6zX6/Htb387Dh06FCtWrIitW7fGyMhIrFy5cuw2Z511VixZsiS2bNkyYc6GDRuip6dn7LJ48eKjHQkAYPLl5le/+lXMmjUrarVafOxjH4t77rkn3vrWt8aePXuis7MzTjzxxHG3nzdvXuzZs2fCvPXr10dvb+/YZdeuXZO+EwAAL5r0Mclly5bFI488Er29vfHv//7vcc0118TmzZuPeoBarZb+WUYAwPFr0uWms7MzzjjjjIg4/OGWP//5z+Of/umf4uqrr47h4eHYv3//uKM3e/fujfnz56cNDADwcqb8Lp9GoxFDQ0NxwQUXREdHR2zatGnse9u2bYunn346VqxYMdUfAwDwqkzqyM369etj9erVsWTJkjhw4EBs3LgxHnjggfjBD34QPT09cd1118W6detizpw5MXv27LjxxhtjxYoVE/6lFABAtkmVm+eeey7+6q/+Kp599tno6emJ8847L37wgx/EX/7lX0ZExJe//OVoa2uLNWvWxNDQUKxatSq+9rWvHZPBAQCOZMrnucnW19cXPT09znMzSc5z09os57mZPOe5mTznuZk857mZvOP6PDcAANORcgMAFCXvmGSyRx99NOWQXeZLSZkvI0VEDAwMpGWdcMIJaVmZc0XkHhaeroe+u7q60rIicl9KqlaraVmZZs6cmZo3ODiYlpX58lvm8s9+Wer0009Py/rNb36TlpW5r81cLyIiZs2alZaV/fJPlux9RtZzwGTWf0duAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICitLd6gD/VbDYjIuLgwYMpeSMjIyk5ERGjo6NpWRERAwMDaVmNRiMtK3OuiIh6vZ6W1daW18czl1nmepadV6lU0rIyZa4XERGDg4NpWS/uhzJUq9W0rMx1NiL3fh44cCAtK3Nf29/fn5YVkbvMsve1WTLX2Yi8bf3FXvBqHoNKM/ORSvDMM8/E4sWLWz0GADAN7dq1KxYtWvSyt5l25abRaMTu3buju7v7ZX/j7Ovri8WLF8euXbti9uzZr+GERFj+rWb5t57HoLUs/9ZqxfJvNptx4MCBWLhw4SsexZ92L0u1tbW9YiP7Y7Nnz7Zit5Dl31qWf+t5DFrL8m+t13r59/T0vKrbeUMxAFAU5QYAKMrrttzUarW45ZZbolartXqU45Ll31qWf+t5DFrL8m+t6b78p90bigEApuJ1e+QGAOBIlBsAoCjKDQBQFOUGACiKcgMAFOV1WW5uv/32eNOb3hRdXV2xfPny+NnPftbqkY4bn/vc56JSqYy7nHXWWa0eq1gPPvhgXHHFFbFw4cKoVCpx7733jvt+s9mMz372s7FgwYKYMWNGrFy5MrZv396aYQv0Ssv/2muvfcn2cPnll7dm2AJt2LAh3v72t0d3d3fMnTs3rrzyyti2bdu42wwODsbatWvjpJNOilmzZsWaNWti7969LZq4LK9m+V9yySUv2QY+9rGPtWji//O6Kzff+c53Yt26dXHLLbfEL3/5yzj//PNj1apV8dxzz7V6tOPG2WefHc8+++zY5ac//WmrRyrWoUOH4vzzz4/bb7/9iN+/7bbb4qtf/Wp8/etfj4cffjhOOOGEWLVqVeonZB/PXmn5R0Rcfvnl47aHb33rW6/hhGXbvHlzrF27Nh566KH44Q9/GCMjI3HZZZfFoUOHxm5z8803x/e///24++67Y/PmzbF79+646qqrWjh1OV7N8o+IuP7668dtA7fddluLJv4jzdeZCy+8sLl27dqxr+v1enPhwoXNDRs2tHCq48ctt9zSPP/881s9xnEpIpr33HPP2NeNRqM5f/785he/+MWx6/bv39+s1WrNb33rWy2YsGx/uvybzWbzmmuuab73ve9tyTzHo+eee64ZEc3Nmzc3m83D63tHR0fz7rvvHrvN448/3oyI5pYtW1o1ZrH+dPk3m83mn//5nzf/5m/+pnVDTeB1deRmeHg4tm7dGitXrhy7rq2tLVauXBlbtmxp4WTHl+3bt8fChQvjtNNOiw9/+MPx9NNPt3qk49KTTz4Ze/bsGbc99PT0xPLly20Pr6EHHngg5s6dG8uWLYuPf/zjsW/fvlaPVKze3t6IiJgzZ05ERGzdujVGRkbGbQNnnXVWLFmyxDZwDPzp8n/RN7/5zTj55JPjnHPOifXr10d/f38rxhtn2n0q+Mt54YUXol6vx7x588ZdP2/evPjtb3/boqmOL8uXL4+77rorli1bFs8++2zceuut8a53vSsee+yx6O7ubvV4x5U9e/ZERBxxe3jxexxbl19+eVx11VWxdOnS2LlzZ/zd3/1drF69OrZs2RLVarXV4xWl0WjETTfdFBdddFGcc845EXF4G+js7IwTTzxx3G1tA/mOtPwjIj70oQ/FqaeeGgsXLoxHH300PvWpT8W2bdviu9/9bgunfZ2VG1pv9erVY/8+77zzYvny5XHqqafGv/3bv8V1113XwsngtfeBD3xg7N/nnntunHfeeXH66afHAw88EJdeemkLJyvP2rVr47HHHvMevxaZaPl/9KMfHfv3ueeeGwsWLIhLL700du7cGaeffvprPeaY19XLUieffHJUq9WXvBN+7969MX/+/BZNdXw78cQT48wzz4wdO3a0epTjzovrvO1h+jjttNPi5JNPtj0ku+GGG+K+++6Ln/zkJ7Fo0aKx6+fPnx/Dw8Oxf//+cbe3DeSaaPkfyfLlyyMiWr4NvK7KTWdnZ1xwwQWxadOmsesajUZs2rQpVqxY0cLJjl8HDx6MnTt3xoIFC1o9ynFn6dKlMX/+/HHbQ19fXzz88MO2hxZ55plnYt++fbaHJM1mM2644Ya455574sc//nEsXbp03PcvuOCC6OjoGLcNbNu2LZ5++mnbQIJXWv5H8sgjj0REtHwbeN29LLVu3bq45ppr4m1ve1tceOGF8ZWvfCUOHToUH/nIR1o92nHhE5/4RFxxxRVx6qmnxu7du+OWW26JarUaH/zgB1s9WpEOHjw47jegJ598Mh555JGYM2dOLFmyJG666ab4whe+EG9+85tj6dKl8ZnPfCYWLlwYV155ZeuGLsjLLf85c+bErbfeGmvWrIn58+fHzp0745Of/GScccYZsWrVqhZOXY61a9fGxo0b43vf+150d3ePvY+mp6cnZsyYET09PXHdddfFunXrYs6cOTF79uy48cYbY8WKFfGOd7yjxdO//r3S8t+5c2ds3Lgx3vOe98RJJ50Ujz76aNx8881x8cUXx3nnndfa4Vv951pH4//9v//XXLJkSbOzs7N54YUXNh966KFWj3TcuPrqq5sLFixodnZ2Nt/4xjc2r7766uaOHTtaPVaxfvKTnzQj4iWXa665ptlsHv5z8M985jPNefPmNWu1WvPSSy9tbtu2rbVDF+Tlln9/f3/zsssua55yyinNjo6O5qmnntq8/vrrm3v27Gn12MU40rKPiOadd945dpuBgYHmX//1Xzff8IY3NGfOnNl83/ve13z22WdbN3RBXmn5P/30082LL764OWfOnGatVmueccYZzb/9279t9vb2tnbwZrNZaTabzdeyTAEAHEuvq/fcAAC8EuUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFOX/A56mhP5YPB/yAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: backprop through batchnorm but all in one go\n",
        "# to complete this challange look at the mathematical expression of the output of batchnorm,\n",
        "# take the derviative w.r.t. its input, simplify the expression, and just write it out\n",
        "\n",
        "# Forward Pass:\n",
        "\n",
        "# BEFORE:\n",
        "# bnmeani = 1/n * hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff ** 2\n",
        "# bnvar = 1 / (n-1) * (bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "# bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# NOW:\n",
        "hpreact_fast = bngain* (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
        "print('max diff:', (hpreact_fast - hpreact).abs().max())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32kcAQEepWVn",
        "outputId": "88d5c58c-35e4-417a-ab09-035fe81c313f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Pass\n",
        "\n",
        "# BEFORE WE HAD:\n",
        "# dbnraw = bngain * dhpreact\n",
        "# dbndiff = bnvar_inv * dbnraw\n",
        "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "# dbnvar = (-0.5 * (bnvar + 1e-5) ** -1.5) * dbnvar_inv\n",
        "# dbndiff2 = (1.0 / (n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
        "# dbndiff += (2 * bndiff) * dbndiff2\n",
        "# dhprebn = dbndiff.clone()\n",
        "# dbnmeani = (-dbndiff).sum(0)\n",
        "# dhprebn += 1.0 / n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "# Calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
        "# (you'll also need to use some of the variables from the forward pass up above)\n",
        "\n",
        "dhprebn = bngain * bnvar_inv / n * (n * dhpreact - dhpreact.sum(0) - n/(n-1) * bnraw * (dhpreact * bnraw).sum(0))\n",
        "\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4NKpgJVsDpG",
        "outputId": "a33f0865-0704-4801-859d-6dae4cc2fb4f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hprebn          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-RzkYMS8GXi",
        "outputId": "402fe4e3-5a72-4af6-eeb5-d5da71ff3520"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]),\n",
              " torch.Size([1, 64]),\n",
              " torch.Size([1, 64]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Putting it all together!\n",
        "\n",
        "* We will train the MLP NN with our own backward pass!"
      ],
      "metadata": {
        "id": "MUYmf0cS8iEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the numbe of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((vocab_size, n_embd),             generator=g)\n",
        "\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
        "\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters on total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "\n",
        "# Same optimization\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "n = batch_size # for convenience\n",
        "lossi = []\n",
        "\n",
        "# We will use this context manger for efficiency once our backward pass in written\n",
        "with torch.no_grad():\n",
        "\n",
        "  # kick off optimization:\n",
        "  for i in range(max_steps):\n",
        "\n",
        "    # MiniBatch Construct\n",
        "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X, Y\n",
        "\n",
        "    # Forward Pass:\n",
        "    emb = C[Xb] # embed the characters into vectors\n",
        "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "\n",
        "    # Linear layer\n",
        "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "\n",
        "    # BatchNorm layer\n",
        "    # ------------------------------------------------------\n",
        "    bnmean = hprebn.mean(0, keepdim=True)\n",
        "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
        "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "    hpreact = bngain * bnraw + bnbias\n",
        "    # ------------------------------------------------------\n",
        "\n",
        "    # Non-linearity\n",
        "    h = torch.tanh(hpreact) # hidden layer\n",
        "    logits = h @ W2 + b2 # output layer\n",
        "    loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "    # Backward Pass\n",
        "    for p in parameters:\n",
        "      p.grad = None\n",
        "    # loss.backward() # use this for comparisons, delete later!\n",
        "\n",
        "    #MANUAL BACKPROP!\n",
        "    # ------------------------------------------------------\n",
        "    dlogits = F.softmax(logits, 1)\n",
        "    dlogits[range(n), Yb] -= 1\n",
        "    dlogits /= n\n",
        "\n",
        "    # 2nd layer of backprop\n",
        "    dh = dlogits @ W2.T\n",
        "    dW2 = h.T @ dlogits\n",
        "    db2 = dlogits.sum(0)\n",
        "\n",
        "    # tanh\n",
        "    dhpreact = (1.0 - h**2) * dh\n",
        "\n",
        "    # batchnorm backprop\n",
        "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "    dhprebn = bngain * bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "\n",
        "    # 1st layer\n",
        "    dembcat = dhprebn @ W1.T\n",
        "    dW1 = embcat.T @ dhprebn\n",
        "    db1 = dhprebn.sum(0)\n",
        "\n",
        "    # Embedding\n",
        "    demb = dembcat.view(emb.shape)\n",
        "    dC = torch.zeros_like(C)\n",
        "\n",
        "    for k in range(Xb.shape[0]):\n",
        "      for j in range(Xb.shape[1]):\n",
        "        ix = Xb[k, j]\n",
        "        dC[ix] += demb[k,j]\n",
        "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "    # ------------------------------------------------------\n",
        "\n",
        "    # Update\n",
        "    lr = 0.1 if i < 100000 else 0.01 # step lr decay\n",
        "    for p, grad in zip(parameters, grads):\n",
        "      #p.data += -lr * p.grad # easy way\n",
        "      p.data += -lr * grad # tough way\n",
        "\n",
        "    # Track stats\n",
        "    if i % 1000 == 0: # print every once in a while\n",
        "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "\n",
        "  # if i >= 100: # delete early breaking when we're ready to train the full NN\n",
        "  #   break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY4qpz-f-YW_",
        "outputId": "ea08f357-829b-4979-fc07-46fbf47e5d23"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12297\n",
            "      0/ 200000: 3.7919\n",
            "   1000/ 200000: 2.2335\n",
            "   2000/ 200000: 2.3303\n",
            "   3000/ 200000: 2.1954\n",
            "   4000/ 200000: 2.2340\n",
            "   5000/ 200000: 2.2879\n",
            "   6000/ 200000: 2.1164\n",
            "   7000/ 200000: 2.4705\n",
            "   8000/ 200000: 2.0275\n",
            "   9000/ 200000: 2.2283\n",
            "  10000/ 200000: 2.1860\n",
            "  11000/ 200000: 1.8704\n",
            "  12000/ 200000: 2.2512\n",
            "  13000/ 200000: 2.2136\n",
            "  14000/ 200000: 2.6538\n",
            "  15000/ 200000: 2.1186\n",
            "  16000/ 200000: 2.5099\n",
            "  17000/ 200000: 2.2530\n",
            "  18000/ 200000: 2.0207\n",
            "  19000/ 200000: 2.4611\n",
            "  20000/ 200000: 2.3882\n",
            "  21000/ 200000: 2.5256\n",
            "  22000/ 200000: 1.8965\n",
            "  23000/ 200000: 2.0199\n",
            "  24000/ 200000: 2.5957\n",
            "  25000/ 200000: 2.3047\n",
            "  26000/ 200000: 2.3019\n",
            "  27000/ 200000: 2.3730\n",
            "  28000/ 200000: 2.0657\n",
            "  29000/ 200000: 2.7245\n",
            "  30000/ 200000: 2.4796\n",
            "  31000/ 200000: 2.2399\n",
            "  32000/ 200000: 2.3801\n",
            "  33000/ 200000: 2.2949\n",
            "  34000/ 200000: 1.9278\n",
            "  35000/ 200000: 2.2171\n",
            "  36000/ 200000: 2.1798\n",
            "  37000/ 200000: 2.0417\n",
            "  38000/ 200000: 2.5814\n",
            "  39000/ 200000: 2.1010\n",
            "  40000/ 200000: 1.9901\n",
            "  41000/ 200000: 2.1990\n",
            "  42000/ 200000: 2.1777\n",
            "  43000/ 200000: 2.3730\n",
            "  44000/ 200000: 1.9787\n",
            "  45000/ 200000: 1.8365\n",
            "  46000/ 200000: 2.2760\n",
            "  47000/ 200000: 2.0900\n",
            "  48000/ 200000: 2.6213\n",
            "  49000/ 200000: 1.9450\n",
            "  50000/ 200000: 2.3220\n",
            "  51000/ 200000: 2.7214\n",
            "  52000/ 200000: 2.2703\n",
            "  53000/ 200000: 2.3950\n",
            "  54000/ 200000: 2.2036\n",
            "  55000/ 200000: 1.9807\n",
            "  56000/ 200000: 2.0782\n",
            "  57000/ 200000: 1.7193\n",
            "  58000/ 200000: 1.7397\n",
            "  59000/ 200000: 2.3703\n",
            "  60000/ 200000: 2.3490\n",
            "  61000/ 200000: 2.2539\n",
            "  62000/ 200000: 2.5819\n",
            "  63000/ 200000: 2.1586\n",
            "  64000/ 200000: 2.2103\n",
            "  65000/ 200000: 2.0780\n",
            "  66000/ 200000: 2.4753\n",
            "  67000/ 200000: 2.5917\n",
            "  68000/ 200000: 1.9681\n",
            "  69000/ 200000: 2.1191\n",
            "  70000/ 200000: 2.0201\n",
            "  71000/ 200000: 2.2606\n",
            "  72000/ 200000: 2.5015\n",
            "  73000/ 200000: 2.3329\n",
            "  74000/ 200000: 1.7989\n",
            "  75000/ 200000: 2.4318\n",
            "  76000/ 200000: 1.7725\n",
            "  77000/ 200000: 2.3488\n",
            "  78000/ 200000: 2.2878\n",
            "  79000/ 200000: 2.1603\n",
            "  80000/ 200000: 2.3228\n",
            "  81000/ 200000: 1.9802\n",
            "  82000/ 200000: 2.4175\n",
            "  83000/ 200000: 1.9548\n",
            "  84000/ 200000: 2.3857\n",
            "  85000/ 200000: 2.0455\n",
            "  86000/ 200000: 2.1537\n",
            "  87000/ 200000: 2.1136\n",
            "  88000/ 200000: 2.3813\n",
            "  89000/ 200000: 2.1991\n",
            "  90000/ 200000: 2.2008\n",
            "  91000/ 200000: 1.9185\n",
            "  92000/ 200000: 2.3812\n",
            "  93000/ 200000: 1.7106\n",
            "  94000/ 200000: 1.9495\n",
            "  95000/ 200000: 2.0211\n",
            "  96000/ 200000: 1.9716\n",
            "  97000/ 200000: 2.2696\n",
            "  98000/ 200000: 2.1275\n",
            "  99000/ 200000: 1.9015\n",
            " 100000/ 200000: 2.0274\n",
            " 101000/ 200000: 1.7683\n",
            " 102000/ 200000: 2.3236\n",
            " 103000/ 200000: 2.0683\n",
            " 104000/ 200000: 2.2364\n",
            " 105000/ 200000: 2.0527\n",
            " 106000/ 200000: 2.2430\n",
            " 107000/ 200000: 2.1624\n",
            " 108000/ 200000: 2.0652\n",
            " 109000/ 200000: 2.2855\n",
            " 110000/ 200000: 2.3436\n",
            " 111000/ 200000: 2.2534\n",
            " 112000/ 200000: 1.8240\n",
            " 113000/ 200000: 2.2553\n",
            " 114000/ 200000: 2.0340\n",
            " 115000/ 200000: 2.1876\n",
            " 116000/ 200000: 2.1196\n",
            " 117000/ 200000: 2.3925\n",
            " 118000/ 200000: 2.3732\n",
            " 119000/ 200000: 2.0873\n",
            " 120000/ 200000: 2.0129\n",
            " 121000/ 200000: 2.2330\n",
            " 122000/ 200000: 2.1692\n",
            " 123000/ 200000: 2.4700\n",
            " 124000/ 200000: 2.6783\n",
            " 125000/ 200000: 2.0013\n",
            " 126000/ 200000: 2.3326\n",
            " 127000/ 200000: 2.1648\n",
            " 128000/ 200000: 2.4407\n",
            " 129000/ 200000: 2.2823\n",
            " 130000/ 200000: 2.4842\n",
            " 131000/ 200000: 1.8482\n",
            " 132000/ 200000: 1.7959\n",
            " 133000/ 200000: 2.2065\n",
            " 134000/ 200000: 2.0653\n",
            " 135000/ 200000: 2.0380\n",
            " 136000/ 200000: 2.0215\n",
            " 137000/ 200000: 1.9976\n",
            " 138000/ 200000: 2.1148\n",
            " 139000/ 200000: 1.8909\n",
            " 140000/ 200000: 2.2097\n",
            " 141000/ 200000: 1.8049\n",
            " 142000/ 200000: 2.0698\n",
            " 143000/ 200000: 2.1727\n",
            " 144000/ 200000: 2.0759\n",
            " 145000/ 200000: 2.1394\n",
            " 146000/ 200000: 2.2214\n",
            " 147000/ 200000: 2.2811\n",
            " 148000/ 200000: 2.3904\n",
            " 149000/ 200000: 2.2817\n",
            " 150000/ 200000: 2.1917\n",
            " 151000/ 200000: 2.2906\n",
            " 152000/ 200000: 1.9851\n",
            " 153000/ 200000: 2.2219\n",
            " 154000/ 200000: 2.2546\n",
            " 155000/ 200000: 2.1075\n",
            " 156000/ 200000: 1.9539\n",
            " 157000/ 200000: 2.1179\n",
            " 158000/ 200000: 2.0378\n",
            " 159000/ 200000: 2.1398\n",
            " 160000/ 200000: 1.9399\n",
            " 161000/ 200000: 2.0338\n",
            " 162000/ 200000: 1.8688\n",
            " 163000/ 200000: 2.1644\n",
            " 164000/ 200000: 2.1531\n",
            " 165000/ 200000: 2.3969\n",
            " 166000/ 200000: 2.2338\n",
            " 167000/ 200000: 2.3192\n",
            " 168000/ 200000: 1.9352\n",
            " 169000/ 200000: 2.3356\n",
            " 170000/ 200000: 1.8558\n",
            " 171000/ 200000: 2.2945\n",
            " 172000/ 200000: 1.9679\n",
            " 173000/ 200000: 2.1673\n",
            " 174000/ 200000: 2.3729\n",
            " 175000/ 200000: 1.9856\n",
            " 176000/ 200000: 1.9273\n",
            " 177000/ 200000: 1.9855\n",
            " 178000/ 200000: 1.8381\n",
            " 179000/ 200000: 2.1701\n",
            " 180000/ 200000: 2.0750\n",
            " 181000/ 200000: 2.1930\n",
            " 182000/ 200000: 2.1932\n",
            " 183000/ 200000: 2.2620\n",
            " 184000/ 200000: 2.4942\n",
            " 185000/ 200000: 2.2939\n",
            " 186000/ 200000: 1.8662\n",
            " 187000/ 200000: 1.7267\n",
            " 188000/ 200000: 2.2433\n",
            " 189000/ 200000: 2.4433\n",
            " 190000/ 200000: 1.8453\n",
            " 191000/ 200000: 2.1066\n",
            " 192000/ 200000: 2.2000\n",
            " 193000/ 200000: 2.0049\n",
            " 194000/ 200000: 1.9691\n",
            " 195000/ 200000: 2.1832\n",
            " 196000/ 200000: 2.1467\n",
            " 197000/ 200000: 2.0443\n",
            " 198000/ 200000: 1.9390\n",
            " 199000/ 200000: 1.6846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# useful for checking your gradients\n",
        "# for p, g in zip(parameters, grads):\n",
        "#   cmp(str(tuple(p.shape)), g, p)"
      ],
      "metadata": {
        "id": "hjtCPz44Jziu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibrate the batch norm at the end of training????????\n",
        "\n",
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtr]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
      ],
      "metadata": {
        "id": "KUlqYXkSJzgH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate train and val loss\n",
        "\n",
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x, y = {\n",
        "      'train': (Xtr, Ytr),\n",
        "      'val':   (Xdev, Ydev),\n",
        "      'test':  (Xte, Yte),\n",
        "  }[split]\n",
        "\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukHeV_-XJzdv",
        "outputId": "279d68f5-1381-438f-8a82-7f301cb9d35f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.071544885635376\n",
            "val 2.1083245277404785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I achieved:\n",
        "# train 2.0718822479248047\n",
        "# val 2.1162495613098145"
      ],
      "metadata": {
        "id": "HCx4kferMHfh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "  out = []\n",
        "  context = [0] * block_size # initialize with all ...\n",
        "  while True:\n",
        "    # --------\n",
        "    # Forward pass:\n",
        "\n",
        "    # Embedding\n",
        "    emb = C[torch.tensor([context])] # (1, block_size, d)\n",
        "    embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "    hpreact = embcat @ W1 + b1\n",
        "    hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "    h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "    logits = h @ W2 + b2 # (N, vocab_size)\n",
        "    #----------\n",
        "\n",
        "    # Sample\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "    context = context[1:] + [ix]\n",
        "    out.append(ix)\n",
        "    if ix == 0:\n",
        "      break\n",
        "\n",
        "\n",
        "  print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x8OyIGFMJAL",
        "outputId": "a9652580-bd6d-47e3-a355-6c4a5cad91e7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mora.\n",
            "mayanniee.\n",
            "mad.\n",
            "ryla.\n",
            "reisa.\n",
            "jendraegelie.\n",
            "kaielin.\n",
            "shi.\n",
            "jen.\n",
            "eden.\n",
            "sananaraelyn.\n",
            "malaia.\n",
            "noshub.\n",
            "roshirael.\n",
            "kindreelynn.\n",
            "novana.\n",
            "ubrence.\n",
            "ryyah.\n",
            "fael.\n",
            "yuma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1eQoXcZNzZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}